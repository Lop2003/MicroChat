# ================================================================
# Enhanced Microcontroller RAG + LINE Bot (Improved Retrieval)
# ================================================================

import os
from dotenv import load_dotenv

# Load environment variables from .env when running locally
load_dotenv()
import re
import sys
import subprocess
from typing import List, Dict, Any

# ================================================================
#  HARDCODED TOKENS (DEV ONLY)
# ================================================================
LINE_CHANNEL_ACCESS_TOKEN = os.getenv('LINE_CHANNEL_ACCESS_TOKEN', "yrYvQZcWle/bU98wyTd8sTw/8huLe1KBovhUL01d0w7MeTltSme+d5XD9V1GRe3mAVnzVVH2GYPIFABhCoOcpITMoAt0iWI8EorycBOLPEFFYEezeYZJPkXOLv5VHRy2ilgplELce3zwirEOKRYZrgdB04t89/1O/w1cDnyilFU=")
LINE_CHANNEL_SECRET = os.getenv('LINE_CHANNEL_SECRET', "15e7919c700c93820c5f94cecaee32d8")
NGROK_AUTHTOKEN = os.getenv('NGROK_AUTHTOKEN', "321Sf8mdH5pVmdJpwAGO25yrGY0_3Bh9AmgNpxyeGapkYtHT8")

# ================================================================
# Imports
# ================================================================
from flask import Flask, request, abort
from pyngrok import ngrok

from linebot.v3 import WebhookHandler
from linebot.v3.exceptions import InvalidSignatureError
from linebot.v3.messaging import (
    Configuration, ApiClient, MessagingApi,
    ReplyMessageRequest, TextMessage
)
from linebot.v3.webhooks import MessageEvent, TextMessageContent

from langchain_community.document_loaders import TextLoader
from langchain.schema import Document
from langchain.text_splitter import MarkdownHeaderTextSplitter, RecursiveCharacterTextSplitter

from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI
from langchain_community.vectorstores import Chroma

from langchain_community.retrievers import BM25Retriever
from langchain.retrievers import EnsembleRetriever, ContextualCompressionRetriever

from langchain_cohere import CohereRerank

from langchain.prompts import PromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser

# Used to securely store your API key
# Removed google.colab.userdata usage; secrets are loaded from environment (.env) via python-dotenv

# ================================================================
# Ensure rank_bm25 available
# ================================================================
def _ensure_rank_bm25():
    try:
        import rank_bm25  # noqa: F401
    except Exception:
        try:
            print("Attempting to install rank_bm25...")
            subprocess.check_call([sys.executable, "-m", "pip", "install", "rank_bm25"])
            print("rank_bm25 installed successfully.")
        except Exception as e:
            print(f"[WARN] install rank_bm25 failed: {e}")

# ================================================================
# Enhanced Query Preprocessing
# ================================================================
def preprocess_question(q: str) -> str:
    """Enhanced query preprocessing for better retrieval"""
    low = q.lower()

    # Remove common question words that don't add search value
    stop_words = ['‡∏Ñ‡∏∑‡∏≠', '‡∏≠‡∏∞‡πÑ‡∏£', '‡πÑ‡∏´‡∏°', '‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà', '‡∏ö‡πâ‡∏≤‡∏á', '‡∏°‡∏µ', '‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ']
    words = q.split()
    filtered_words = [w for w in words if w.lower() not in stop_words]

    # Add domain-specific expansions
    expansions = []

    # Mapping for better retrieval - Enhanced for project question
    keyword_mapping = {
        r"(‡∏™‡∏≠‡∏ö‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥|‡πÇ‡∏Ñ‡∏£‡∏á‡∏á‡∏≤‡∏ô|‡∏Å‡∏≤‡∏£‡∏™‡∏≠‡∏ö|project|assessment|‡∏Ç‡πâ‡∏≠‡∏Å‡∏≥‡∏´‡∏ô‡∏î|‡πÄ‡∏Å‡∏ì‡∏ë‡πå)": "‡πÇ‡∏Ñ‡∏£‡∏á‡∏á‡∏≤‡∏ô‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏£‡∏≤‡∏¢‡∏ß‡∏¥‡∏ä‡∏≤ Microcontroller ‡πÅ‡∏ö‡πà‡∏á‡∏Å‡∏•‡∏∏‡πà‡∏° 5-6 ‡∏Ñ‡∏ô ‡πÄ‡∏Å‡πá‡∏ö‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô 20 ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô ‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏Å‡∏≤‡∏£‡πÉ‡∏´‡πâ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô ‡∏Ç‡πâ‡∏≠‡∏Å‡∏≥‡∏´‡∏ô‡∏î ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÇ‡∏Ñ‡∏£‡∏á‡∏á‡∏≤‡∏ô ‡∏û‡∏£‡∏µ‡πÄ‡∏ã‡∏ô‡∏ï‡πå 30 ‡∏ô‡∏≤‡∏ó‡∏µ ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô 20 ‡∏´‡∏ô‡πâ‡∏≤ PDF",
        r"(‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô|‡∏Ç‡∏≤‡∏î‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô|‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏≠‡∏¥‡πÄ‡∏•‡πá‡∏Å‡∏ó‡∏£‡∏≠‡∏ô‡∏¥‡∏Å‡∏™‡πå|‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ)": "‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏≠‡∏¥‡πÄ‡∏•‡πá‡∏Å‡∏ó‡∏£‡∏≠‡∏ô‡∏¥‡∏Å‡∏™‡πå ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô Microcontroller ‡πÑ‡∏î‡πâ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà ‡∏ú‡∏•‡∏Å‡∏£‡∏∞‡∏ó‡∏ö‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ç‡∏≤‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ",
        r"(‡∏≠‡∏∏‡∏õ‡∏Å‡∏£‡∏ì‡πå|‡πÉ‡∏ä‡πâ‡∏≠‡∏∞‡πÑ‡∏£|components|‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á)": "‡∏≠‡∏∏‡∏õ‡∏Å‡∏£‡∏ì‡πå‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏ß‡∏á‡∏à‡∏£ Microcontroller input output devices ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ã‡∏±‡∏Å‡∏ú‡πâ‡∏≤ ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏õ‡∏£‡∏±‡∏ö‡∏≠‡∏≤‡∏Å‡∏≤‡∏®",
        r"(‡∏ï‡πà‡∏≠‡∏¢‡∏≠‡∏î|‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏ï‡πà‡∏≠|advanced|‡∏ß‡∏¥‡∏ä‡∏≤‡πÑ‡∏´‡∏ô)": "‡∏ï‡πà‡∏≠‡∏¢‡∏≠‡∏î‡πÑ‡∏õ‡∏™‡∏π‡πà‡∏ß‡∏¥‡∏ä‡∏≤‡πÉ‡∏î Embedded Systems IoT Robotics Communication Networking",
        r"(‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î|programming|‡∏†‡∏≤‡∏©‡∏≤|‡∏ù‡∏∂‡∏Å)": "‡∏ù‡∏∂‡∏Å‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î‡∏†‡∏≤‡∏©‡∏≤‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô C programming ‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£ ‡∏ä‡∏ô‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•",
        r"(‡∏ß‡∏¥‡∏ä‡∏≤.*microcontroller|microcontroller.*‡∏Ñ‡∏∑‡∏≠)": "Microcontroller ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£ ‡∏≠‡∏∏‡∏õ‡∏Å‡∏£‡∏ì‡πå‡∏≠‡∏¥‡πÄ‡∏•‡πá‡∏Å‡∏ó‡∏£‡∏≠‡∏ô‡∏¥‡∏Å‡∏™‡πå ‡∏Ñ‡∏≠‡∏°‡∏û‡∏¥‡∏ß‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏Ç‡∏ô‡∏≤‡∏î‡πÄ‡∏•‡πá‡∏Å ‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô",
    }

    original_query = ' '.join(filtered_words) if filtered_words else q

    for pattern, expansion in keyword_mapping.items():
        if re.search(pattern, low):
            expansions.append(expansion)

    if expansions:
        return f"{original_query} {' '.join(expansions)}"

    return original_query

# ================================================================
# Initialize Enhanced RAG chain
# ================================================================
def initialize_rag_chain(md_file: str = "micro_rag_optimized.md"):
    print("‚è≥ Loading and indexing documents...")
    if not os.path.exists(md_file):
        raise FileNotFoundError(f"‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå {md_file}")

    loader = TextLoader(md_file, encoding="utf-8")
    docs = loader.load()
    full_text = docs[0].page_content

    # Enhanced document splitting strategy
    # First split by headers to maintain context
    header_splitter = MarkdownHeaderTextSplitter(
        headers_to_split_on=[
            ("#", "Header 1"),
            ("##", "Header 2"),
            ("###", "Header 3"),
            ("####", "Header 4"),
        ],
        strip_headers=False
    )

    header_docs = header_splitter.split_text(full_text)

    # Then use recursive splitter for size control
    rc_splitter = RecursiveCharacterTextSplitter(
        chunk_size=800,  # Smaller chunks for better precision
        chunk_overlap=200,  # More overlap for context preservation
        separators=["\n\n", "\n", "„ÄÇ", ".", " ", ""]
    )

    final_docs = rc_splitter.split_documents(header_docs)

    # Add more metadata to help with retrieval
    for i, doc in enumerate(final_docs):
        doc.metadata['chunk_id'] = i
        # Extract keywords from content for better matching
        content_lower = doc.page_content.lower()
        keywords = []
        if '‡πÇ‡∏Ñ‡∏£‡∏á‡∏á‡∏≤‡∏ô' in content_lower or 'project' in content_lower or '‡∏™‡∏≠‡∏ö‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥' in content_lower:
            keywords.append('‡πÇ‡∏Ñ‡∏£‡∏á‡∏á‡∏≤‡∏ô')
        if '‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô' in content_lower or '‡∏Ç‡∏≤‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ' in content_lower:
            keywords.append('‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô')
        if '‡∏ï‡πà‡∏≠‡∏¢‡∏≠‡∏î' in content_lower or '‡∏ß‡∏¥‡∏ä‡∏≤' in content_lower:
            keywords.append('‡∏ï‡πà‡∏≠‡∏¢‡∏≠‡∏î')
        if '‡∏≠‡∏∏‡∏õ‡∏Å‡∏£‡∏ì‡πå' in content_lower or 'devices' in content_lower:
            keywords.append('‡∏≠‡∏∏‡∏õ‡∏Å‡∏£‡∏ì‡πå')
        # Convert the list of keywords to a comma-separated string
        doc.metadata['keywords'] = ', '.join(keywords) if keywords else None

    print(f"‚úÖ Document split into {len(final_docs)} enhanced chunks.")

    # Load API keys
    GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')
    if GOOGLE_API_KEY is None:
        print("[WARN] GOOGLE_API_KEY is missing. Please set it in your environment variables.")
    embeddings = GoogleGenerativeAIEmbeddings(
        model="models/embedding-001",
        google_api_key=GOOGLE_API_KEY
    )

    vectorstore = Chroma.from_documents(
        documents=final_docs,
        embedding=embeddings
    )
    print("‚úÖ Enhanced ChromaDB vector store created.")

    # Enhanced retriever configuration
    vect_retriever = vectorstore.as_retriever(
        search_type="mmr",
        search_kwargs={
            "k": 20,  # Get more candidates
            "fetch_k": 80,  # Increase fetch pool
            "lambda_mult": 0.7  # Balance diversity vs relevance
        }
    )

    # BM25 with enhanced settings
    _ensure_rank_bm25()
    bm25_retriever = BM25Retriever.from_documents(final_docs)
    bm25_retriever.k = 20

    # Ensemble with adjusted weights - favor BM25 for exact keyword matching
    hybrid_retriever = EnsembleRetriever(
        retrievers=[vect_retriever, bm25_retriever],
        weights=[0.6, 0.4]  # Slightly favor BM25 for Thai text
    )

    # Enhanced reranking
    try:
        COHERE_API_KEY = os.getenv('COHERE_API_KEY')
        if COHERE_API_KEY is None:
            print("[WARN] COHERE_API_KEY is missing. Please set it in your environment variables.")
        compressor = CohereRerank(
            model="rerank-multilingual-v3.0",
            top_n=10,  # Keep more results for better coverage
            cohere_api_key=COHERE_API_KEY
        )
        retrieval = ContextualCompressionRetriever(
            base_compressor=compressor,
            base_retriever=hybrid_retriever
        )
        print("‚úÖ Using Enhanced Cohere Reranker.")
    except Exception as e:
        print(f"Could not initialize Cohere Reranker: {e}")
        retrieval = hybrid_retriever

    # Enhanced LLM and Prompt
    GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')
    if GOOGLE_API_KEY is None:
        print("[WARN] GOOGLE_API_KEY is missing. Please set it in your environment variables.")
    llm = ChatGoogleGenerativeAI(
        model="gemini-2.0-flash",
        temperature=0,
        convert_system_message_to_human=True,
        google_api_key=GOOGLE_API_KEY
    )

    # Improved prompt template
    template = """‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡πÑ‡∏°‡πÇ‡∏Ñ‡∏£‡∏Ñ‡∏≠‡∏ô‡πÇ‡∏ó‡∏£‡∏•‡πÄ‡∏•‡∏≠‡∏£‡πå ‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£

‡∏Å‡∏é‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö:
- ‡πÉ‡∏ä‡πâ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å Context
- ‡∏ï‡∏≠‡∏ö‡∏ï‡∏£‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô ‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏á‡πà‡∏≤‡∏¢
- ‡∏´‡πâ‡∏≤‡∏°‡πÉ‡∏™‡πà‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏´‡∏°‡∏≤‡∏¢ * ‡∏´‡∏£‡∏∑‡∏≠ bullet points ‡πÅ‡∏ö‡∏ö *
- ‡∏´‡πâ‡∏≤‡∏°‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô "‡∏à‡∏≤‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡∏°‡∏≤" ‡∏´‡∏£‡∏∑‡∏≠ "(‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà X)"
- ‡πÉ‡∏ä‡πâ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏¢‡πà‡∏≠‡∏´‡∏ô‡πâ‡∏≤‡∏ò‡∏£‡∏£‡∏°‡∏î‡∏≤ ‡∏´‡∏£‡∏∑‡∏≠‡∏Ç‡∏∂‡πâ‡∏ô‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡πÉ‡∏´‡∏°‡πà‡∏î‡πâ‡∏ß‡∏¢ - ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
- ‡∏´‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£"

Context:
{context}

‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°: {question}

‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö:"""

    ANSWER_PROMPT = PromptTemplate.from_template(template)

    def format_docs(docs: List[Document]) -> str:
        formatted = []
        for i, doc in enumerate(docs, 1):
            content = doc.page_content.strip()
            if content:
                # Clean up all formatting issues
                content = re.sub(r'\*+\s*\*+', '', content)  # Remove multiple asterisks
                content = re.sub(r'^\*+\s*', '', content, flags=re.MULTILINE)  # Remove leading asterisks
                content = re.sub(r'\*+\s*$', '', content, flags=re.MULTILINE)  # Remove trailing asterisks
                content = re.sub(r'\*+([^*]+)\*+', r'\1', content)  # Remove asterisks around text
                content = re.sub(r'\n\s*\*\s*', '\n', content)  # Remove bullet asterisks
                content = re.sub(r'‡∏à‡∏≤‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡∏°‡∏≤[,:\s]*', '', content)  # Remove reference phrases
                content = re.sub(r'\(‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà\s*\d+[,\s]*\d*\)', '', content)  # Remove data references
                formatted.append(content)
        return "\n\n".join(formatted[:10])  # Increase to 10 chunks for better coverage

    rag_chain = (
        {
            "context": retrieval,
            "question": RunnablePassthrough(),
        }
        | RunnablePassthrough.assign(context=lambda x: format_docs(x["context"]))
        | ANSWER_PROMPT
        | llm
        | StrOutputParser()
    )

    print("‚úÖ Enhanced RAG Chain ready")
    return rag_chain

# ================================================================
# LINE Bot + Flask (unchanged)
# ================================================================
app = Flask(__name__)

configuration = Configuration(access_token=LINE_CHANNEL_ACCESS_TOKEN)
handler = WebhookHandler(LINE_CHANNEL_SECRET)

rag_chain = initialize_rag_chain("micro_rag_optimized.md")

@app.route("/callback", methods=['POST'])
def callback():
    signature = request.headers.get('X-Line-Signature', "")
    body = request.get_data(as_text=True)
    try:
        handler.handle(body, signature)
    except InvalidSignatureError:
        abort(400)
    return "OK"

def safe_reply(api: MessagingApi, reply_token: str, text: str):
    api.reply_message_with_http_info(
        ReplyMessageRequest(
            reply_token=reply_token,
            messages=[TextMessage(text=text[:4900])]
        )
    )

# Simple chat responses for casual questions
def get_simple_response(question: str) -> str:
    """Handle simple casual questions directly"""
    q_lower = question.lower().strip()

    casual_responses = {
        # Greetings
        r'(‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ|hello|hi|‡∏î‡∏µ|hey)': "‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö! ‡∏°‡∏µ‡∏≠‡∏∞‡πÑ‡∏£‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö Microcontroller ‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏≤‡∏Å‡∏ñ‡∏≤‡∏°‡πÑ‡∏´‡∏°‡∏Ñ‡∏£‡∏±‡∏ö?",
        r'(‡πÑ‡∏á|‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏á|‡∏¢‡∏±‡∏á‡πÑ‡∏á)': "‡∏™‡∏ö‡∏≤‡∏¢‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö! ‡∏°‡∏µ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö Microcontroller ‡πÑ‡∏´‡∏°‡∏Ñ‡∏£‡∏±‡∏ö?",

        # Weather/general chat
        r'(‡∏≠‡∏≤‡∏Å‡∏≤‡∏®|‡∏ù‡∏ô|‡∏£‡πâ‡∏≠‡∏ô|‡∏´‡∏ô‡∏≤‡∏ß|‡∏≠‡∏∏‡∏ì‡∏´‡∏†‡∏π‡∏°‡∏¥)': "‡∏ú‡∏°‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏™‡∏†‡∏≤‡∏û‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡πÑ‡∏î‡πâ‡∏Ñ‡∏£‡∏±‡∏ö ‡πÅ‡∏ï‡πà‡∏ñ‡πâ‡∏≤‡∏≠‡∏¢‡∏≤‡∏Å‡∏£‡∏π‡πâ‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á Microcontroller ‡∏°‡∏µ‡∏≠‡∏∞‡πÑ‡∏£‡∏ñ‡∏≤‡∏°‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢‡∏ô‡∏∞‡∏Ñ‡∏£‡∏±‡∏ö!",
        r'(‡∏Å‡∏¥‡∏ô|‡∏≠‡∏≤‡∏´‡∏≤‡∏£|‡∏´‡∏¥‡∏ß|‡∏≠‡∏£‡πà‡∏≠‡∏¢)': "‡∏ú‡∏°‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡πÑ‡∏î‡πâ‡∏Ñ‡∏£‡∏±‡∏ö ‡πÅ‡∏ï‡πà‡∏ñ‡πâ‡∏≤‡∏≠‡∏¢‡∏≤‡∏Å‡∏£‡∏π‡πâ‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á Microcontroller ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ñ‡∏≤‡∏°‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢!",

        # Simple questions
        r'(‡∏ó‡∏≥‡πÑ‡∏°|‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡πÑ‡∏£|why)': "‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö Microcontroller ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ñ‡∏≤‡∏°‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö!",
        r'(‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì|thanks|thank you)': "‡∏¢‡∏¥‡∏ô‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö! ‡∏°‡∏µ‡∏≠‡∏∞‡πÑ‡∏£‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö Microcontroller ‡∏≠‡∏¢‡∏≤‡∏Å‡∏ñ‡∏≤‡∏°‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡πÑ‡∏´‡∏°‡∏Ñ‡∏£‡∏±‡∏ö?",

        # Numbers or short queries
        r'^[0-9\s\.]+$': "‡∏ú‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á Microcontroller ‡∏Ñ‡∏£‡∏±‡∏ö ‡∏°‡∏µ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö Microcontroller ‡πÑ‡∏´‡∏°‡∏Ñ‡∏£‡∏±‡∏ö?",
    }

    for pattern, response in casual_responses.items():
        if re.search(pattern, q_lower):
            return response

    return None


@handler.add(MessageEvent, message=TextMessageContent)
def handle_message(event):
    q_raw = event.message.text

    # Check for simple casual questions first
    simple_ans = get_simple_response(q_raw)
    if simple_ans:
        print(f"üí¨ Q: {q_raw} -> [Simple Response]")
        print(f"ü§ñ Ans: {simple_ans}")
        with ApiClient(configuration) as api_client:
            safe_reply(MessagingApi(api_client), event.reply_token, simple_ans)
        return

    # Process with RAG for technical questions
    q_processed = preprocess_question(q_raw)
    print(f"üí¨ Q: {q_raw} -> {q_processed}")

    try:
        ans = rag_chain.invoke(q_processed)
        # Additional fallback if no relevant answer found
        if "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£" in ans and len(q_raw) > 10:
            # Try with original question
            ans_fallback = rag_chain.invoke(q_raw)
            if "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£" not in ans_fallback:
                ans = ans_fallback
    except Exception as e:
        ans = f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {e}"

    print(f"ü§ñ Ans: {ans}")
    with ApiClient(configuration) as api_client:
        safe_reply(MessagingApi(api_client), event.reply_token, ans)

# ================================================================
# Run server + Ngrok (unchanged)
# ================================================================
if __name__ == "__main__":
    ngrok.set_auth_token(NGROK_AUTHTOKEN)

    # Disconnect any existing tunnels
    try:
        tunnels = ngrok.get_tunnels()
        for tunnel in tunnels:
            ngrok.disconnect(tunnel.public_url)
    except Exception as e:
        print(f"Could not disconnect existing ngrok tunnels: {e}")

    public_url = ngrok.connect(5000)
    print("="*60)
    print("üöÄ Enhanced LINE Bot Online")
    print(f"üîó Webhook URL: {public_url.public_url}/callback")
    print("="*60)
    app.run(port=5000, debug=False)